{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":21755,"databundleVersionId":1475600,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":424869,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":346297,"modelId":367571}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport os\nfrom PIL import Image\nimport zipfile","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:45:07.993348Z","iopub.execute_input":"2025-06-04T17:45:07.994337Z","iopub.status.idle":"2025-06-04T17:45:07.999880Z","shell.execute_reply.started":"2025-06-04T17:45:07.994293Z","shell.execute_reply":"2025-06-04T17:45:07.998602Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load generator\nG = tf.keras.models.load_model('/kaggle/input/monet_generator_scm1/keras/default/1/monet_generator.keras')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:45:21.984232Z","iopub.execute_input":"2025-06-04T17:45:21.984646Z","iopub.status.idle":"2025-06-04T17:45:23.152177Z","shell.execute_reply.started":"2025-06-04T17:45:21.984562Z","shell.execute_reply":"2025-06-04T17:45:23.150865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm.notebook import tqdm\n\n# Decode and preprocess function\ndef decode_image(example):\n    features = {\"image\": tf.io.FixedLenFeature([], tf.string)}\n    example = tf.io.parse_single_example(example, features)\n    image = tf.image.decode_jpeg(example[\"image\"], channels=3)\n    image = tf.image.resize(image, [256, 256])\n    image = (tf.cast(image, tf.float32) / 127.5) - 1.0  # Normalize to [-1, 1]\n    return image\n\n# Load photos from TFRecord\nphoto_paths = tf.io.gfile.glob('/kaggle/input/gan-getting-started/photo_tfrec/*.tfrec')\nphoto_ds = tf.data.TFRecordDataset(photo_paths).map(decode_image).take(7028)\n\n# Generate Monet-style images with progress bar\nprint(\"Generating Monet-style images...\")\n# Create zip and write images directly (no disk output!)\nwith zipfile.ZipFile(\"images.zip\", \"w\") as zipf:\n    for i, img in tqdm(enumerate(photo_ds), total=7028):\n        # Run generator\n        generated = G(tf.expand_dims(img, 0), training=False)[0]\n        generated = (generated + 1.0) * 127.5\n        generated = tf.clip_by_value(generated, 0, 255)\n        arr = tf.cast(generated, tf.uint8).numpy()\n\n        # Convert to JPEG in-memory\n        buffer = io.BytesIO()\n        Image.fromarray(arr).save(buffer, format='JPEG')\n        buffer.seek(0)\n\n        # Write to zip (no intermediate files!)\n        zipf.writestr(f\"{i}.jpg\", buffer.read())\n\nprint(\"âœ… Done! images.zip is ready for submission.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:47:50.025069Z","iopub.execute_input":"2025-06-04T17:47:50.025562Z","iopub.status.idle":"2025-06-04T20:01:31.098836Z","shell.execute_reply.started":"2025-06-04T17:47:50.025513Z","shell.execute_reply":"2025-06-04T20:01:31.097854Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\n\n# Decode and preprocess image\ndef decode_image(example):\n    features = {\"image\": tf.io.FixedLenFeature([], tf.string)}\n    example = tf.io.parse_single_example(example, features)\n    image = tf.image.decode_jpeg(example[\"image\"], channels=3)\n    image = tf.image.resize(image, [256, 256])\n    image = (tf.cast(image, tf.float32) / 127.5) - 1.0  # Normalize to [-1, 1]\n    return image\n\n# Load the TFRecord dataset\nphoto_paths = tf.io.gfile.glob('/kaggle/input/gan-getting-started/photo_tfrec/*.tfrec')\nphoto_ds = tf.data.TFRecordDataset(photo_paths).map(decode_image)\n\n# Convert to list to sample randomly (only safe since we have enough memory)\nphoto_images = list(photo_ds.take(1000))  # Load first 1000 images only to keep things efficient\n\n# Select N random images\nN = 5\nsamples = random.sample(photo_images, N)\n\n# Plot\nplt.figure(figsize=(10, 4 * N))\nfor i, img in enumerate(samples):\n    generated = G(tf.expand_dims(img, 0), training=False)[0]\n\n    # Convert both to [0,1] for display\n    original = (img + 1) / 2.0\n    generated = (generated + 1) / 2.0\n\n    # Original image\n    plt.subplot(N, 2, 2 * i + 1)\n    plt.imshow(original.numpy())\n    plt.axis('off')\n    plt.title(\"Original Photo\")\n\n    # Generated Monet\n    plt.subplot(N, 2, 2 * i + 2)\n    plt.imshow(generated.numpy())\n    plt.axis('off')\n    plt.title(\"Monet Style\")\n    \nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T20:06:57.415814Z","iopub.execute_input":"2025-06-04T20:06:57.416196Z","iopub.status.idle":"2025-06-04T20:07:05.571970Z","shell.execute_reply.started":"2025-06-04T20:06:57.416166Z","shell.execute_reply":"2025-06-04T20:07:05.570843Z"}},"outputs":[],"execution_count":null}]}